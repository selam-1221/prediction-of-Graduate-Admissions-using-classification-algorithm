{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88319501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "0           1        337          118                  4  4.5   4.5  9.65   \n",
      "1           2        324          107                  4  4.0   4.5  8.87   \n",
      "2           3        316          104                  3  3.0   3.5  8.00   \n",
      "3           4        322          110                  3  3.5   2.5  8.67   \n",
      "4           5        314          103                  2  2.0   3.0  8.21   \n",
      "\n",
      "   Research  chance of admit   \n",
      "0         1              0.92  \n",
      "1         1              0.76  \n",
      "2         1              0.72  \n",
      "3         1              0.80  \n",
      "4         0              0.65  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   chance of admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n",
      "None\n",
      "Distribution of the Target Variable (Chance_of_Admit):\n",
      "0.71    0.046\n",
      "0.64    0.038\n",
      "0.73    0.036\n",
      "0.72    0.032\n",
      "0.79    0.032\n",
      "        ...  \n",
      "0.38    0.004\n",
      "0.36    0.004\n",
      "0.43    0.002\n",
      "0.39    0.002\n",
      "0.37    0.002\n",
      "Name: Chance_of_Admit, Length: 61, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Load and Understand the Data\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Admission_Predict_Ver1.1.csv')\n",
    "\n",
    "# Check the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Check the data types and missing values\n",
    "print(df.info())\n",
    "\n",
    "\n",
    "df=df.rename(columns={'Serial No.':'Serial_No','GRE Score':'GRE_Score','TOEFL Score':'TOEFL_Score','University Rating':'University_rating','LOR ':'LOR'\n",
    "                     ,'chance of admit ':'Chance_of_Admit'})\n",
    "\n",
    "\n",
    "# Analyze the distribution of the target variable 'Chance of Admit'\n",
    "target_variable = 'Chance_of_Admit'\n",
    "target_distribution = df[target_variable].value_counts(normalize=True)\n",
    "print(\"Distribution of the Target Variable (Chance_of_Admit):\")\n",
    "print(target_distribution)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf5f1739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE_Score  TOEFL_Score  University_rating  SOP  LOR  CGPA  Research  \\\n",
       "0          337          118                  4  4.5  4.5  9.65         1   \n",
       "1          324          107                  4  4.0  4.5  8.87         1   \n",
       "2          316          104                  3  3.0  3.5  8.00         1   \n",
       "3          322          110                  3  3.5  2.5  8.67         1   \n",
       "4          314          103                  2  2.0  3.0  8.21         0   \n",
       "..         ...          ...                ...  ...  ...   ...       ...   \n",
       "495        332          108                  5  4.5  4.0  9.02         1   \n",
       "496        337          117                  5  5.0  5.0  9.87         1   \n",
       "497        330          120                  5  4.5  5.0  9.56         1   \n",
       "498        312          103                  4  4.0  5.0  8.43         0   \n",
       "499        327          113                  4  4.5  4.5  9.04         0   \n",
       "\n",
       "     Chance_of_Admit  \n",
       "0               0.92  \n",
       "1               0.76  \n",
       "2               0.72  \n",
       "3               0.80  \n",
       "4               0.65  \n",
       "..               ...  \n",
       "495             0.87  \n",
       "496             0.96  \n",
       "497             0.93  \n",
       "498             0.73  \n",
       "499             0.84  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Serial_No'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_greater_than_0_5 = df[df[target_variable] >= 0.5].shape[0]\n",
    "num_less_than_0_5 = df[df[target_variable] < 0.5].shape[0]\n",
    "\n",
    "print(f\"Number of values greater than 0.5: {num_greater_than_0_5}\")\n",
    "print(f\"Number of values less than 0.5: {num_less_than_0_5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86c94f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i have to use classification techniques for this dataset so i have to convert the continous variable of chanceof admit \n",
    "#in to dicrete  variable using threshold value\n",
    "\n",
    "\n",
    "\n",
    "# Define the threshold to convert 'Chance of Admit' into a binary classification problem\n",
    "threshold = 0.5\n",
    "\n",
    "# Convert 'Chance of Admit' to binary labels (0 or 1)\n",
    "df['Admission_Status'] = np.where(df['Chance_of_Admit'] >= threshold, 1, 0)\n",
    "\n",
    "# Drop the original 'Chance of Admit' column\n",
    "df.drop(columns=['Chance_of_Admit'], inplace=True)\n",
    "\n",
    "# Separate features (X) and the binary target variable (y)\n",
    "X = df.drop(columns=['Admission_Status'])\n",
    "y = df['Admission_Status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f34865e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Feature Selection/Engineering (optional)\n",
    "# You can perform feature selection/engineering based on domain knowledge and feature importance analysis.\n",
    "\n",
    "# Step 4: Train a Classification Model (Random Forest Classifier)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87039305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Model Evaluation\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d144ef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Admission Status: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example input data for prediction\n",
    "input_data = pd.DataFrame({\n",
    "    'GRE_Score': [320],\n",
    "    'TOEFL_Score': [110],\n",
    "    'University_rating': [5],\n",
    "    'SOP': [4.5],\n",
    "    'LOR': [4.0],\n",
    "    'CGPA': [9.0],\n",
    "    'Research': [1]\n",
    "})\n",
    "\n",
    "# Make predictions on the input data\n",
    "predicted_admission_status = rf_classifier.predict(input_data)\n",
    "\n",
    "# Print the prediction\n",
    "print(\"Predicted Admission Status:\", predicted_admission_status[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36f3e2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.94\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.44      0.57         9\n",
      "           1       0.95      0.99      0.97        91\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.87      0.72      0.77       100\n",
      "weighted avg       0.93      0.94      0.93       100\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 4  5]\n",
      " [ 1 90]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "\n",
    "# Generate a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Step 6: Make Predictions (Optional)\n",
    "# You can use the trained model to make predictions on new, unseen data.\n",
    "\n",
    "# Step 7: Communicate Results (Optional)\n",
    "# Present the model's performance and insights in a clear and concise manner.\n",
    "\n",
    "# Step 8: Iterate and Improve (Optional)\n",
    "# If needed, iterate and try different approaches to improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 1: Understanding the Dataset\n",
    "\n",
    "Download the dataset from the provided Kaggle link and load it into your preferred data analysis environment (Python, R, etc.).\n",
    "Explore the dataset to understand its structure, features, and target variable (in this case, \"Chance of Admit\").\n",
    "Check for missing values, data types, and any data preprocessing steps that may be required.\n",
    "Step 2: Data Preprocessing\n",
    "\n",
    "Handle missing data: Impute or remove missing values based on the nature of the missing data.\n",
    "Feature engineering: Analyze and transform existing features or create new features that might improve the model's performance.\n",
    "Feature scaling: If necessary, scale numerical features to bring them to a similar range, which helps the model convergence.\n",
    "Step 3: Splitting the Data\n",
    "\n",
    "Split the dataset into a training set and a testing set. The training set will be used to train the classification model, and the testing set will be used for evaluation.\n",
    "Step 4: Selecting a Classification Model\n",
    "\n",
    "Research and choose a suitable classification algorithm for the problem. Commonly used algorithms include Logistic Regression, Decision Trees, Random Forest, Support Vector Machines, etc.\n",
    "Import the necessary libraries for the selected algorithm.\n",
    "Step 5: Model Training\n",
    "\n",
    "Train the selected classification model on the training set using the fit() function or the appropriate method for the chosen algorithm.\n",
    "Step 6: Model Evaluation\n",
    "\n",
    "Predict the admission probabilities on the testing set using the trained model.\n",
    "Evaluate the model's performance using relevant metrics such as accuracy, precision, recall, F1-score, ROC-AUC, etc.\n",
    "Step 7: Model Tuning (Optional)\n",
    "\n",
    "If the model's performance is not satisfactory, consider hyperparameter tuning or trying different algorithms to improve the results.\n",
    "Use techniques like cross-validation or grid search to find the best hyperparameters for the model.\n",
    "Step 8: Interpretation and Visualization\n",
    "\n",
    "Interpret the results and understand which features are most influential in predicting graduate admissions.\n",
    "Visualize important features, model performance metrics, and any other relevant insights.\n",
    "Step 9: Conclusion and Reporting\n",
    "\n",
    "Summarize the findings, including the chosen model's performance and any insights gained from the analysis.\n",
    "Create a report or presentation to present your work and results to stakeholders or supervisors.\n",
    "Step 10: Deployment (Optional)\n",
    "\n",
    "If required, deploy the trained model to a production environment for real-time predictions.\n",
    "Remember, this sequence may vary depending on the specific challenges you encounter during the analysis. As a data science intern, it's essential to be open to learning and adapt to different scenarios as you work on the project. Good luck with your graduate admissions prediction project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125ea06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
